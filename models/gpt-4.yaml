name: gpt-4
backend: llama-cpp
parameters:
  model: Hermes-3-Llama-3.2-3B-Q4_K_M.gguf
  temperature: 0.7
  top_k: 40
  top_p: 0.9
  max_tokens: 2048
context_size: 4096
threads: 7
f16: true
mmap: true
low_vram: true
gpu_layers: 0
